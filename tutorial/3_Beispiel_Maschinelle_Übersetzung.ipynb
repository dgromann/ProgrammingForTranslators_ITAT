{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtUA528LpvIwoSjywBcMRE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dgromann/ProgrammingForTranslators_ITAT/blob/main/tutorial/3_Beispiel_Maschinelle_%C3%9Cbersetzung.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Programmieren fÃ¼r Ãœbersetzer:innen - Beispiel Maschinelle Ãœbersetzung**\n",
        "\n",
        "\n",
        "Dieses Notebook zeigt wie ein bereits trainiertes Modell von [HuggingFace](https://huggingface.co/) geladen werden kann und eine Anfrage an das Modell gestellt werden kann.\n",
        "\n",
        "Um externe Softwarebibliotheken zu verwenden, mÃ¼ssen diese installiert werden. Eine Softwarebibliothek oder Programmbibliothek stellt eine Sammlung von Unterprogrammen dar, die LÃ¶sungen fÃ¼r Problemstellungen anbietet. Anstatt bei Null zu beginnen, kann ich meinen Code auf dem Code anderer aufbauen, indem ich diese existierenden LÃ¶sungen importiere bzw. installiere.\n",
        "\n",
        "Auf Google Colab werden Softwarebibliotheken mit dem Befehl `!pip install`+ dem Namen der Bibliothek installiert.\n",
        "\n",
        "# Letkion 1: Maschinelle Ãœbersetzung mit HuggingFace\n",
        "\n",
        "[HuggingFace](https://huggingface.co/) ist eine Plattform fÃ¼r Deep Learning und Data Science. Dort werden trainierte Modelle fÃ¼r verschiedene Aufgabenstellungen sowie DatensÃ¤tze und Tutorials zur VerfÃ¼gung gestellt.  \n",
        "\n",
        "FÃ¼r die Verwendung von sogenannten Transformer-Modellen von HuggingFace muss die entsprechende Bibliothek erst installiert werden.\n",
        "\n",
        "ðŸ‘‹ âš’ **Aufgabe** ðŸ‘‹ âš’ <br>\n",
        "FÃ¼hren Sie den folgenden Code aus."
      ],
      "metadata": {
        "id": "CArHJGQ6p-yJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67Unel9vp8t7"
      },
      "outputs": [],
      "source": [
        "!pip install transformers # Um die Modelle auf HuggingFace verwenden zu kÃ¶nnen\n",
        "!pip install evaluate # Eine Bibliothek fÃ¼r MT-Evaluationsmetriken"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Als kleines Beispiel zur Verwendung von HugginFace laden wir das Modell [T5-small](https://huggingface.co/t5-small), ein Modell fÃ¼r maschinelle Ãœbersetzung fÃ¼r English, FranzÃ¶sisch, RomÃ¤nisch, und Deutsch."
      ],
      "metadata": {
        "id": "FaQ7RggAqcGp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "translator = pipeline(\"translation_en_to_de\", model=\"t5-small\")\n",
        "translator(\"This is a test\")"
      ],
      "metadata": {
        "id": "AGzgEREqqtP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ‘‹ âš’ **Aufgabe** ðŸ‘‹ âš’ <br>\n",
        "Ãœbersetzen Sie einen anderen Satz Ihrer Wahl."
      ],
      "metadata": {
        "id": "96Vdx_TMuoLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#FÃ¼gen Sie Ihr Beispiel und Ihren Code hier ein"
      ],
      "metadata": {
        "id": "P2pC9FVkuocp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Letkion 1: Evaluierung\n",
        "\n",
        "Wir kÃ¶nnen die Ergebnisse dann auch automatisch evaluieren.\n",
        "\n",
        "### **Edit Distance**\n",
        "\n",
        " Die einfachste Form der Evaluierung ist die sogenannte Edit-Distanz oder Levenshtein-Distanz. Hierbei wird gezÃ¤hlt wieviele Buchstaben hinzugefÃ¼gt, gelÃ¶scht oder ersetzt werden mÃ¼ssen, um einen String in einen anderen umzuwandeln."
      ],
      "metadata": {
        "id": "2C5ujyvkvYLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "reference = \"This is a test\"\n",
        "candidate = \"This is not a test\"\n",
        "\n",
        "edit_distance = nltk.edit_distance(reference, candidate, transpositions=False)\n",
        "print(edit_distance)"
      ],
      "metadata": {
        "id": "X3w2SiIow5At"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ‘‹ âš’ **Aufgabe** ðŸ‘‹ âš’ <br>\n",
        "Ã„ndern Sie die folgende Code-Zelle um die Ausgabe des T5-small Modells mit einer Ãœbersetzung Ihrer Wahl zu vergleichen."
      ],
      "metadata": {
        "id": "ObDf54uyxB7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fragen Sie eine\n",
        "source_text = \"Your text here\"\n",
        "target_text = \"Ihr Text hier\"\n",
        "\n",
        "# FÃ¼gen Sie hier die Ãœbersetzung des T5-Modells hinzu\n",
        "candidate =\n",
        "\n",
        "edit_distance = nltk.edit_distance(target_text, candidate, transpositions=False)\n",
        "print(edit_distance)"
      ],
      "metadata": {
        "id": "R1bQ971RxLXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **BLEU**\n",
        "\n",
        "Ein Metrik zur Evaluierung die am weitesten verbreitet ist, ist der sogenannte Bilingual Evaluation Understudy (BLEU [Linktext](https://en.wikipedia.org/wiki/BLEU)-Score. Eine einfach zu verwendenden Implementierung ist die Softwarebibliothek SacreBLEU von HuggingFace.\n",
        "\n",
        "ðŸ‘‹ âš’ **Aufgabe** ðŸ‘‹ âš’ <br>\n",
        "Vergleichen Sie die Ausgabe des T5-small Modells mit Ihrer eigenen Ãœbersetzung mithilfe von SacreBLEU."
      ],
      "metadata": {
        "id": "UyiQlZtuxa-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from evaluate import load\n",
        "\n",
        "# SacreBLEU erwartet eine Liste als Input\n",
        "source_text = [\"This is a test\", \"Do you have a more interesting example?\"]\n",
        "reference = [\"Das ist ein Test\", \"Haben Sie ein interessanteres Beispiel?\"]\n",
        "\n",
        "# Da SacreBLEU eine Liste benÃ¶tigt, mÃ¼ssen wir jeden Satz einzeln Ã¼bersetzen und in einer Liste speichern\n",
        "candidate =\n",
        "\n",
        "\n",
        "sacrebleu = load(\"sacrebleu\")\n",
        "results = sacrebleu.compute(predictions=candidate, references=reference)\n",
        "\n",
        "# Das ist eine Liste von allen Variablen die SacreBLEU bereitstellt\n",
        "print(list(results.keys()))\n",
        "print(\"SacreBLEU Metrik:\")\n",
        "print(round(results[\"score\"], 1))"
      ],
      "metadata": {
        "id": "jHttNlPwvltN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}